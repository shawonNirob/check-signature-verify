{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b57684-9ad5-4fd1-b2b7-ec0fcd0b11b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find document contour. Trying alternative method...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import imutils\n",
    "\n",
    "class DocumentCropper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def order_points(self, pts):\n",
    "        \"\"\"Order points in clockwise order: top-left, top-right, bottom-right, bottom-left\"\"\"\n",
    "        # Sort the points based on their x-coordinates\n",
    "        xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "        \n",
    "        # Grab the left-most and right-most points from the sorted x-coordinate points\n",
    "        leftMost = xSorted[:2, :]\n",
    "        rightMost = xSorted[2:, :]\n",
    "        \n",
    "        # Sort the left-most points according to their y-coordinates\n",
    "        leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "        (tl, bl) = leftMost\n",
    "        \n",
    "        # Use the distance to find top-right and bottom-right\n",
    "        D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "        (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "        \n",
    "        return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "    \n",
    "    def four_point_transform(self, image, pts):\n",
    "        \"\"\"Apply perspective transform to get bird's eye view\"\"\"\n",
    "        rect = self.order_points(pts)\n",
    "        (tl, tr, br, bl) = rect\n",
    "        \n",
    "        # Compute the width of the new image\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "        \n",
    "        # Compute the height of the new image\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "        \n",
    "        # Destination points for the perspective transform\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [maxWidth - 1, 0],\n",
    "            [maxWidth - 1, maxHeight - 1],\n",
    "            [0, maxHeight - 1]], dtype=\"float32\")\n",
    "        \n",
    "        # Compute the perspective transform matrix and apply it\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    def find_document_contour(self, image):\n",
    "        \"\"\"Find the largest rectangular contour (white document like bank check)\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply bilateral filter to reduce noise while keeping edges sharp\n",
    "        filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "        \n",
    "        # Apply threshold to highlight white/light areas (documents)\n",
    "        # This helps separate white documents from darker backgrounds\n",
    "        _, thresh = cv2.threshold(filtered, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Morphological operations to clean up the binary image\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Edge detection on the thresholded image\n",
    "        edged = cv2.Canny(thresh, 50, 150)\n",
    "        \n",
    "        # Dilate edges to connect broken contours\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        edged = cv2.dilate(edged, kernel, iterations=1)\n",
    "        \n",
    "        # Find contours\n",
    "        contours = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        # Look for the largest rectangular contour that's likely a document\n",
    "        for c in contours:\n",
    "            area = cv2.contourArea(c)\n",
    "            \n",
    "            # Skip very small contours\n",
    "            if area < 10000:\n",
    "                continue\n",
    "                \n",
    "            # Approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.015 * peri, True)  # More flexible approximation\n",
    "            \n",
    "            # Check if it's roughly rectangular (4 points) and large enough\n",
    "            if len(approx) == 4:\n",
    "                # Additional check: ensure it's not too thin (aspect ratio check)\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = float(w) / h\n",
    "                \n",
    "                # Bank checks typically have aspect ratio between 2:1 and 3:1\n",
    "                if 1.5 < aspect_ratio < 4.0 and area > 20000:\n",
    "                    return approx\n",
    "            \n",
    "            # If we can't find exact 4 points, try with more flexible approximation\n",
    "            elif 4 <= len(approx) <= 8:\n",
    "                # For irregular contours, use bounding rectangle\n",
    "                rect = cv2.minAreaRect(c)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                \n",
    "                # Check area and aspect ratio\n",
    "                width = rect[1][0]\n",
    "                height = rect[1][1]\n",
    "                if width > 0 and height > 0:\n",
    "                    aspect_ratio = max(width, height) / min(width, height)\n",
    "                    if 1.5 < aspect_ratio < 4.0 and area > 20000:\n",
    "                        return box.reshape(4, 2).astype(np.float32)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def enhance_image(self, image):\n",
    "        \"\"\"Enhance image quality for better edge detection\"\"\"\n",
    "        # Convert to LAB color space\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        # Apply CLAHE to L channel\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        \n",
    "        # Merge channels and convert back to BGR\n",
    "        enhanced = cv2.merge([l, a, b])\n",
    "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        return enhanced\n",
    "    \n",
    "    def crop_document(self, image_path, output_path=None, show_steps=False):\n",
    "        \"\"\"Main function to crop document from image\"\"\"\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image from {image_path}\")\n",
    "        \n",
    "        orig = image.copy()\n",
    "        \n",
    "        # Resize image for processing (optional, for large images)\n",
    "        ratio = image.shape[0] / 500.0\n",
    "        image = imutils.resize(image, height=500)\n",
    "        \n",
    "        # Enhance image quality\n",
    "        enhanced = self.enhance_image(image)\n",
    "        \n",
    "        if show_steps:\n",
    "            cv2.imshow(\"Original\", image)\n",
    "            cv2.imshow(\"Enhanced\", enhanced)\n",
    "            \n",
    "            # Show the preprocessing steps for debugging\n",
    "            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "            filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "            _, thresh = cv2.threshold(filtered, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "            cv2.imshow(\"Grayscale\", gray)\n",
    "            cv2.imshow(\"Filtered\", filtered)\n",
    "            cv2.imshow(\"Threshold\", thresh)\n",
    "        \n",
    "        # Find document contour\n",
    "        document_contour = self.find_document_contour(enhanced)\n",
    "        \n",
    "        if document_contour is None:\n",
    "            print(\"Could not find document contour. Trying alternative method...\")\n",
    "            # Alternative: Look for the largest white region\n",
    "            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours = imutils.grab_contours(contours)\n",
    "            \n",
    "            if contours:\n",
    "                # Get the largest white region\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                if cv2.contourArea(largest_contour) > 10000:\n",
    "                    # Use bounding rectangle of the largest white area\n",
    "                    rect = cv2.minAreaRect(largest_contour)\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    document_contour = box.reshape(4, 2).astype(np.float32)\n",
    "                else:\n",
    "                    # Fallback: use center portion of image\n",
    "                    h, w = image.shape[:2]\n",
    "                    margin = min(w, h) // 10\n",
    "                    document_contour = np.array([\n",
    "                        [margin, margin], \n",
    "                        [w-margin, margin], \n",
    "                        [w-margin, h-margin], \n",
    "                        [margin, h-margin]\n",
    "                    ], dtype=np.float32)\n",
    "            else:\n",
    "                # Last resort: use most of the image\n",
    "                h, w = image.shape[:2]\n",
    "                document_contour = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)\n",
    "        \n",
    "        # Scale the contour back to original image size\n",
    "        if document_contour is not None:\n",
    "            document_contour = document_contour.reshape(4, 2) * ratio\n",
    "        \n",
    "        if show_steps:\n",
    "            # Draw the contour on the original image\n",
    "            display_orig = orig.copy()\n",
    "            cv2.drawContours(display_orig, [document_contour.astype(int)], -1, (0, 255, 0), 3)\n",
    "            cv2.imshow(\"Document Contour\", imutils.resize(display_orig, height=500))\n",
    "        \n",
    "        # Apply perspective transform\n",
    "        warped = self.four_point_transform(orig, document_contour.reshape(4, 2))\n",
    "        \n",
    "        if show_steps:\n",
    "            cv2.imshow(\"Cropped Document\", imutils.resize(warped, height=500))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        # Save the result if output path is provided\n",
    "        if output_path:\n",
    "            cv2.imwrite(output_path, warped)\n",
    "            print(f\"Cropped document saved to {output_path}\")\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    def crop_multiple_documents(self, image_path, output_dir=\"cropped_docs\", min_area=10000):\n",
    "        \"\"\"Detect and crop multiple documents from a single image\"\"\"\n",
    "        import os\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        orig = image.copy()\n",
    "        \n",
    "        # Resize for processing\n",
    "        ratio = image.shape[0] / 500.0\n",
    "        image = imutils.resize(image, height=500)\n",
    "        \n",
    "        # Enhance image\n",
    "        enhanced = self.enhance_image(image)\n",
    "        \n",
    "        # Convert to grayscale and detect edges\n",
    "        gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edged = cv2.Canny(blurred, 75, 200)\n",
    "        \n",
    "        # Find contours\n",
    "        contours = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        doc_count = 0\n",
    "        cropped_docs = []\n",
    "        \n",
    "        for c in contours:\n",
    "            # Skip small contours\n",
    "            if cv2.contourArea(c) < min_area / (ratio ** 2):\n",
    "                continue\n",
    "            \n",
    "            # Approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "            \n",
    "            # If contour has 4 points, it might be a document\n",
    "            if len(approx) == 4:\n",
    "                # Scale back to original size\n",
    "                scaled_contour = approx.reshape(4, 2) * ratio\n",
    "                \n",
    "                # Apply perspective transform\n",
    "                try:\n",
    "                    warped = self.four_point_transform(orig, scaled_contour)\n",
    "                    \n",
    "                    # Save the cropped document\n",
    "                    output_path = os.path.join(output_dir, f\"document_{doc_count}.jpg\")\n",
    "                    cv2.imwrite(output_path, warped)\n",
    "                    cropped_docs.append(output_path)\n",
    "                    doc_count += 1\n",
    "                    \n",
    "                    print(f\"Document {doc_count} saved to {output_path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing contour: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Total documents found and cropped: {doc_count}\")\n",
    "        return cropped_docs\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    cropper = DocumentCropper()\n",
    "    \n",
    "    # Example 1: Crop single document\n",
    "    try:\n",
    "        # Replace 'input_image.jpg' with your image path\n",
    "        cropped = cropper.crop_document('test_image_processing.jpeg', show_steps=True)\n",
    "        print(\"Document cropping completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 2: Crop multiple documents from one image\n",
    "    try:\n",
    "        documents = cropper.crop_multiple_documents('input_image.jpg')\n",
    "        print(f\"Cropped {len(documents)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 3: Just get the cropped image without saving\n",
    "    try:\n",
    "        cropped_image = cropper.crop_document('input_image.jpg')\n",
    "        # Now you can process cropped_image further\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef25be0a-91ee-4650-b837-81bce670d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: module 'numpy' has no attribute 'int0'\n",
      "Error: 'NoneType' object has no attribute 'copy'\n",
      "Error: Could not load image from input_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.495] global loadsave.cpp:268 findDecoder imread_('input_image.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@0.495] global loadsave.cpp:268 findDecoder imread_('input_image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import imutils\n",
    "\n",
    "class DocumentCropper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def order_points(self, pts):\n",
    "        \"\"\"Order points in clockwise order: top-left, top-right, bottom-right, bottom-left\"\"\"\n",
    "        # Sort the points based on their x-coordinates\n",
    "        xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "        \n",
    "        # Grab the left-most and right-most points from the sorted x-coordinate points\n",
    "        leftMost = xSorted[:2, :]\n",
    "        rightMost = xSorted[2:, :]\n",
    "        \n",
    "        # Sort the left-most points according to their y-coordinates\n",
    "        leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "        (tl, bl) = leftMost\n",
    "        \n",
    "        # Use the distance to find top-right and bottom-right\n",
    "        D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "        (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "        \n",
    "        return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "    \n",
    "    def four_point_transform(self, image, pts):\n",
    "        \"\"\"Apply perspective transform to get bird's eye view\"\"\"\n",
    "        rect = self.order_points(pts)\n",
    "        (tl, tr, br, bl) = rect\n",
    "        \n",
    "        # Compute the width of the new image\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "        \n",
    "        # Compute the height of the new image\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "        \n",
    "        # Destination points for the perspective transform\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [maxWidth - 1, 0],\n",
    "            [maxWidth - 1, maxHeight - 1],\n",
    "            [0, maxHeight - 1]], dtype=\"float32\")\n",
    "        \n",
    "        # Compute the perspective transform matrix and apply it\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    def find_document_contour(self, image):\n",
    "        \"\"\"Find document contour using edge detection approach for bank checks\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Method 1: Enhanced edge detection approach\n",
    "        # Apply bilateral filter to smooth while preserving edges\n",
    "        filtered = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "        \n",
    "        # Adaptive thresholding to handle varying lighting\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(filtered, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                              cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Edge detection with multiple techniques\n",
    "        # Canny edge detection\n",
    "        edges1 = cv2.Canny(filtered, 30, 80)\n",
    "        \n",
    "        # Gradient-based edge detection\n",
    "        sobelx = cv2.Sobel(filtered, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(filtered, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        edges2 = np.sqrt(sobelx**2 + sobely**2).astype(np.uint8)\n",
    "        edges2 = cv2.threshold(edges2, 50, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        # Combine edge detection methods\n",
    "        edges = cv2.bitwise_or(edges1, edges2)\n",
    "        \n",
    "        # Morphological operations to connect broken edges and close gaps\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "        \n",
    "        # Find contours\n",
    "        contours = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "        \n",
    "        if not contours:\n",
    "            return None\n",
    "            \n",
    "        # Sort contours by area\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        # Method 2: Look for document-like contours\n",
    "        for i, c in enumerate(contours[:10]):  # Check top 10 largest contours\n",
    "            area = cv2.contourArea(c)\n",
    "            \n",
    "            # Skip very small contours\n",
    "            if area < 5000:\n",
    "                continue\n",
    "            \n",
    "            # Get bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            \n",
    "            # Check if it looks like a document (reasonable aspect ratio)\n",
    "            aspect_ratio = float(w) / h if h > 0 else 0\n",
    "            \n",
    "            # Bank checks typically have aspect ratio between 1.8 and 3.2\n",
    "            if 1.5 < aspect_ratio < 4.0:\n",
    "                # Try to approximate the contour\n",
    "                peri = cv2.arcLength(c, True)\n",
    "                \n",
    "                # Try different approximation levels\n",
    "                for epsilon in [0.01, 0.015, 0.02, 0.03, 0.04]:\n",
    "                    approx = cv2.approxPolyDP(c, epsilon * peri, True)\n",
    "                    \n",
    "                    if len(approx) == 4:\n",
    "                        # Check if the approximated contour is reasonable\n",
    "                        approx_area = cv2.contourArea(approx)\n",
    "                        if approx_area > area * 0.7:  # Should be at least 70% of original area\n",
    "                            return approx\n",
    "                \n",
    "                # If we can't get exactly 4 points, use minimum area rectangle\n",
    "                rect = cv2.minAreaRect(c)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                \n",
    "                # Verify this looks like a document\n",
    "                rect_area = cv2.contourArea(box)\n",
    "                if rect_area > area * 0.8 and rect_area > 10000:\n",
    "                    return box.reshape(4, 2).astype(np.float32)\n",
    "        \n",
    "        # Method 3: If no good contour found, try with different parameters\n",
    "        # More aggressive edge detection\n",
    "        edges_aggressive = cv2.Canny(gray, 20, 60)\n",
    "        kernel_large = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        edges_aggressive = cv2.morphologyEx(edges_aggressive, cv2.MORPH_CLOSE, kernel_large, iterations=3)\n",
    "        \n",
    "        contours2 = cv2.findContours(edges_aggressive, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours2 = imutils.grab_contours(contours2)\n",
    "        \n",
    "        if contours2:\n",
    "            # Get the largest contour\n",
    "            largest_contour = max(contours2, key=cv2.contourArea)\n",
    "            if cv2.contourArea(largest_contour) > 8000:\n",
    "                # Use minimum area rectangle\n",
    "                rect = cv2.minAreaRect(largest_contour)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                return box.reshape(4, 2).astype(np.float32)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def enhance_image(self, image):\n",
    "        \"\"\"Enhance image quality for better edge detection\"\"\"\n",
    "        # Convert to LAB color space\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        # Apply CLAHE to L channel\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        \n",
    "        # Merge channels and convert back to BGR\n",
    "        enhanced = cv2.merge([l, a, b])\n",
    "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        return enhanced\n",
    "    \n",
    "    def crop_document(self, image_path, output_path=None, show_steps=False):\n",
    "        \"\"\"Main function to crop document from image\"\"\"\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image from {image_path}\")\n",
    "        \n",
    "        orig = image.copy()\n",
    "        \n",
    "        # Resize image for processing (optional, for large images)\n",
    "        ratio = image.shape[0] / 500.0\n",
    "        image = imutils.resize(image, height=500)\n",
    "        \n",
    "        # Enhance image quality\n",
    "        enhanced = self.enhance_image(image)\n",
    "        \n",
    "        if show_steps:\n",
    "            cv2.imshow(\"Original\", image)\n",
    "            cv2.imshow(\"Enhanced\", enhanced)\n",
    "            \n",
    "            # Show the preprocessing steps for debugging\n",
    "            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "            filtered = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "            \n",
    "            # Show edge detection steps\n",
    "            edges1 = cv2.Canny(filtered, 30, 80)\n",
    "            sobelx = cv2.Sobel(filtered, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            sobely = cv2.Sobel(filtered, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            edges2 = np.sqrt(sobelx**2 + sobely**2).astype(np.uint8)\n",
    "            edges2 = cv2.threshold(edges2, 50, 255, cv2.THRESH_BINARY)[1]\n",
    "            combined_edges = cv2.bitwise_or(edges1, edges2)\n",
    "            \n",
    "            cv2.imshow(\"Grayscale\", gray)\n",
    "            cv2.imshow(\"Filtered\", filtered)\n",
    "            cv2.imshow(\"Canny Edges\", edges1)\n",
    "            cv2.imshow(\"Sobel Edges\", edges2)\n",
    "            cv2.imshow(\"Combined Edges\", combined_edges)\n",
    "        \n",
    "        # Find document contour\n",
    "        document_contour = self.find_document_contour(enhanced)\n",
    "        \n",
    "        if document_contour is None:\n",
    "            print(\"Could not find document contour. Trying alternative method...\")\n",
    "            # Alternative: Look for rectangular shapes in the image using HoughLines\n",
    "            gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Try to detect lines that form a rectangle\n",
    "            edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "            \n",
    "            if lines is not None and len(lines) >= 4:\n",
    "                # This is a simplified approach - in practice, you'd need to\n",
    "                # find intersecting lines that form a rectangle\n",
    "                print(\"Found some lines, using center crop as fallback\")\n",
    "            \n",
    "            # Fallback: Use a center crop that's likely to contain the document\n",
    "            h, w = image.shape[:2]\n",
    "            margin_w = w // 8  # 12.5% margin on each side\n",
    "            margin_h = h // 8  # 12.5% margin on top/bottom\n",
    "            document_contour = np.array([\n",
    "                [margin_w, margin_h], \n",
    "                [w-margin_w, margin_h], \n",
    "                [w-margin_w, h-margin_h], \n",
    "                [margin_w, h-margin_h]\n",
    "            ], dtype=np.float32)\n",
    "        \n",
    "        # Scale the contour back to original image size\n",
    "        if document_contour is not None:\n",
    "            document_contour = document_contour.reshape(4, 2) * ratio\n",
    "        \n",
    "        if show_steps:\n",
    "            # Draw the contour on the original image\n",
    "            display_orig = orig.copy()\n",
    "            cv2.drawContours(display_orig, [document_contour.astype(int)], -1, (0, 255, 0), 3)\n",
    "            cv2.imshow(\"Document Contour\", imutils.resize(display_orig, height=500))\n",
    "        \n",
    "        # Apply perspective transform\n",
    "        warped = self.four_point_transform(orig, document_contour.reshape(4, 2))\n",
    "        \n",
    "        if show_steps:\n",
    "            cv2.imshow(\"Cropped Document\", imutils.resize(warped, height=500))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        # Save the result if output path is provided\n",
    "        if output_path:\n",
    "            cv2.imwrite(output_path, warped)\n",
    "            print(f\"Cropped document saved to {output_path}\")\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    def crop_multiple_documents(self, image_path, output_dir=\"cropped_docs\", min_area=10000):\n",
    "        \"\"\"Detect and crop multiple documents from a single image\"\"\"\n",
    "        import os\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        orig = image.copy()\n",
    "        \n",
    "        # Resize for processing\n",
    "        ratio = image.shape[0] / 500.0\n",
    "        image = imutils.resize(image, height=500)\n",
    "        \n",
    "        # Enhance image\n",
    "        enhanced = self.enhance_image(image)\n",
    "        \n",
    "        # Convert to grayscale and detect edges\n",
    "        gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edged = cv2.Canny(blurred, 75, 200)\n",
    "        \n",
    "        # Find contours\n",
    "        contours = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        doc_count = 0\n",
    "        cropped_docs = []\n",
    "        \n",
    "        for c in contours:\n",
    "            # Skip small contours\n",
    "            if cv2.contourArea(c) < min_area / (ratio ** 2):\n",
    "                continue\n",
    "            \n",
    "            # Approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "            \n",
    "            # If contour has 4 points, it might be a document\n",
    "            if len(approx) == 4:\n",
    "                # Scale back to original size\n",
    "                scaled_contour = approx.reshape(4, 2) * ratio\n",
    "                \n",
    "                # Apply perspective transform\n",
    "                try:\n",
    "                    warped = self.four_point_transform(orig, scaled_contour)\n",
    "                    \n",
    "                    # Save the cropped document\n",
    "                    output_path = os.path.join(output_dir, f\"document_{doc_count}.jpg\")\n",
    "                    cv2.imwrite(output_path, warped)\n",
    "                    cropped_docs.append(output_path)\n",
    "                    doc_count += 1\n",
    "                    \n",
    "                    print(f\"Document {doc_count} saved to {output_path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing contour: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Total documents found and cropped: {doc_count}\")\n",
    "        return cropped_docs\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    cropper = DocumentCropper()\n",
    "    \n",
    "    # Example 1: Crop single document\n",
    "    try:\n",
    "        # Replace 'input_image.jpg' with your image path\n",
    "        cropped = cropper.crop_document('test_image_processing.jpeg', show_steps=True)\n",
    "        print(\"Document cropping completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 2: Crop multiple documents from one image\n",
    "    try:\n",
    "        documents = cropper.crop_multiple_documents('input_image.jpg')\n",
    "        print(f\"Cropped {len(documents)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 3: Just get the cropped image without saving\n",
    "    try:\n",
    "        cropped_image = cropper.crop_document('input_image.jpg')\n",
    "        # Now you can process cropped_image further\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f231d4-d36a-45bf-8ae9-b8c2a5381d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
